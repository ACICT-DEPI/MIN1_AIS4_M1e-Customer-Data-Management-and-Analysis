{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a2a79cf-a375-4417-87f9-4feed37cae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "# Create engine using SQLAlchemy for both databases\n",
    "engine_cm = create_engine('mssql+pyodbc://ABDALLAH\\\\MSSQLSERVER2/CustomerManagement?trusted_connection=yes&driver=SQL+Server')\n",
    "engine_dwh = create_engine('mssql+pyodbc://ABDALLAH\\\\MSSQLSERVER2/CustomerManagementDWH?trusted_connection=yes&driver=SQL+Server')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91bc37b7-1ee8-465a-90dd-b6905c536d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Extract data from Customers table in CustomerManagement DB\n",
    "query_extract_customers = \"SELECT * FROM Customers\"\n",
    "customers_df = pd.read_sql(query_extract_customers, engine_cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3e088df-7de6-400c-ac9d-9609f553bdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data: remove columns that are not present in Customers_Dim\n",
    "customers_df = customers_df.drop(columns=['ShippingAddress', 'BillingAddress'])\n",
    "\n",
    "# Rename or transform other columns if needed\n",
    "customers_df = customers_df.rename(columns={\n",
    "    'CustomerID': 'CustomerID',\n",
    "    'FullName': 'FullName',\n",
    "    'Email': 'Email',\n",
    "    'PhoneNumber': 'PhoneNumber',\n",
    "    'DateOfBirth': 'DateOfBirth',\n",
    "    'LoyaltyPoints': 'LoyaltyPoints',\n",
    "    'Preferences': 'PreferredCategories'  # Assuming preferences map to this\n",
    "})\n",
    "\n",
    "# Handle any null values or necessary transformations\n",
    "customers_df['LoyaltyPoints'].fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef06287c-f6cb-4258-9ae3-622b4215370f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data into Customers_Dim table in CustomerManagementDWH\n",
    "customers_df.to_sql('Customers_Dim', engine_dwh, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbbb735a-5e52-473c-822a-7bccb5dab377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from Payments_Dim table in CustomerManagementDWH\n",
    "query_extract_payments = \"SELECT PaymentID, PaymentMethod FROM Payments_Dim\"\n",
    "payments_dim_df = pd.read_sql(query_extract_payments, engine_dwh)\n",
    "\n",
    "# Create a mapping dictionary\n",
    "payment_method_to_id = dict(zip(payments_dim_df['PaymentMethod'], payments_dim_df['PaymentID']))\n",
    "\n",
    "# Define the get_payment_id function\n",
    "def get_payment_id(payment_method):\n",
    "    return payment_method_to_id.get(payment_method, None)  # Returns None if payment method is not found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7f1cff0-b322-4a98-b420-9c24ff2b8d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the get_payment_id function to the PaymentMethod column in orders_df\n",
    "orders_df['PaymentID'] = orders_df['PaymentMethod'].apply(lambda x: get_payment_id(x))\n",
    "\n",
    "# Drop the PaymentMethod column as it is no longer needed\n",
    "orders_df = orders_df.drop(columns=['PaymentMethod'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4219f17-3c07-409a-b493-a2cba8aa368c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Date_Dim from the Data Warehouse\n",
    "query_extract_date_dim = \"SELECT DateID, Date FROM Date_Dim\"\n",
    "date_dim_df = pd.read_sql(query_extract_date_dim, engine_dwh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7eade42-b4de-4a7b-8a0f-36e7aec176dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from Date to DateID\n",
    "date_mapping = dict(zip(date_dim_df['Date'], date_dim_df['DateID']))\n",
    "\n",
    "# Map OrderDate to DateID\n",
    "orders_df['OrderDateID'] = orders_df['OrderDateID'].apply(lambda x: date_mapping.get(x.date(), None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38584570-04f4-44bd-a431-ed2e6580b76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Address_Dim from Data Warehouse\n",
    "query_extract_address_dim = \"SELECT AddressID, FullAddress FROM Address_Dim\"\n",
    "address_dim_df = pd.read_sql(query_extract_address_dim, engine_dwh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96b4af1c-ac38-49d4-a89b-2cacef0bdcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from FullAddress to AddressID\n",
    "address_mapping = dict(zip(address_dim_df['FullAddress'], address_dim_df['AddressID']))\n",
    "\n",
    "# Map ShippingAddress and BillingAddress to AddressID\n",
    "orders_df['ShippingAddressID'] = orders_df['ShippingAddressID'].apply(lambda x: address_mapping.get(x, None))\n",
    "orders_df['BillingAddressID'] = orders_df['BillingAddressID'].apply(lambda x: address_mapping.get(x, None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2b18451-7c3a-4a70-9985-5ee74d07aa22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShippingAddressID    100\n",
      "BillingAddressID     100\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(orders_df[['ShippingAddressID', 'BillingAddressID']].isnull().sum())  # Should be 0 if all addresses were mapped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1b5b802-a1cd-4571-bd2d-9095e20ea473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data into Orders_Fact table in CustomerManagementDWH\n",
    "orders_df.to_sql('Orders_Fact', engine_dwh, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28bb0d47-0f53-47ac-98e1-0d7a2ac7d78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PaymentID  PaymentMethod         PaymentDate  Amount\n",
      "0          1         PayPal 2024-07-24 17:59:23  323.32\n",
      "1          2         PayPal 2023-12-09 17:59:23  200.32\n",
      "2          3  Bank Transfer 2024-07-05 17:59:23  323.32\n",
      "3          4     Debit Card 2024-03-06 17:59:23  304.07\n",
      "4          5     Debit Card 2024-03-08 17:59:23  428.00\n"
     ]
    }
   ],
   "source": [
    "# Extract data from Payments table in the CustomerManagement database\n",
    "payments_df = pd.read_sql(\"SELECT PaymentID, PaymentMethod, PaymentDate, Amount FROM Payments\", engine_cm)\n",
    "print(payments_df.head())  # Display first few rows to check the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f5f88a6-7283-47f0-8e31-7b890ffbd8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PaymentID                 int64\n",
      "PaymentMethod            object\n",
      "PaymentDate      datetime64[ns]\n",
      "Amount                  float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Perform any necessary transformations (e.g., converting PaymentDate format, mapping PaymentMethods, handling missing values)\n",
    "\n",
    "# Example transformation: Convert PaymentDate to a proper date format\n",
    "payments_df['PaymentDate'] = pd.to_datetime(payments_df['PaymentDate'])\n",
    "\n",
    "# Ensure that all necessary fields are present and have valid values\n",
    "payments_df = payments_df.dropna(subset=['PaymentID', 'PaymentMethod', 'PaymentDate', 'Amount'])\n",
    "\n",
    "print(payments_df.dtypes)  # Check data types to ensure they're correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9934fc97-b4cd-4873-a000-a1b9efaa875b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data into Payments_Dim table in CustomerManagementDWH\n",
    "payments_df.to_sql('Payments_Dim', engine_dwh, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "125e752e-7682-4417-a0e5-e50d9ad65877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ProductID ProductName    Category     Brand  Price  Rating\n",
      "0          1   Product 1  Category 9   Brand 4  26.07     4.0\n",
      "1          2   Product 2  Category 2   Brand 2  23.00     3.8\n",
      "2          3   Product 3  Category 7  Brand 10  60.05     2.5\n",
      "3          4   Product 4  Category 3   Brand 1  58.66     3.8\n",
      "4          5   Product 5  Category 5   Brand 1  92.61     4.8\n"
     ]
    }
   ],
   "source": [
    "# Extract data from Products, Categories, and Brands tables in CustomerManagement\n",
    "products_query = \"\"\"\n",
    "SELECT \n",
    "    p.ProductID, \n",
    "    p.ProductName, \n",
    "    c.CategoryName AS Category, \n",
    "    b.BrandName AS Brand, \n",
    "    p.Price, \n",
    "    p.Rating\n",
    "FROM Products p\n",
    "LEFT JOIN Categories c ON p.CategoryID = c.CategoryID\n",
    "LEFT JOIN Brands b ON p.BrandID = b.BrandID\n",
    "\"\"\"\n",
    "\n",
    "products_df = pd.read_sql(products_query, engine_cm)\n",
    "print(products_df.head())  # Display first few rows to check the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e66f9a0-65a2-401e-951f-4c2f4036088e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProductID        int64\n",
      "ProductName     object\n",
      "Category        object\n",
      "Brand           object\n",
      "Price          float64\n",
      "Rating         float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Perform any necessary transformations (e.g., handling missing values, data type conversion)\n",
    "# For example, ensuring 'Price' is numeric and 'Rating' is within a valid range\n",
    "\n",
    "# Drop any rows with missing mandatory values\n",
    "products_df = products_df.dropna(subset=['ProductID', 'ProductName', 'Category', 'Brand', 'Price'])\n",
    "\n",
    "# Check the data types to ensure everything is correct\n",
    "print(products_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "394dd551-b9a8-4643-a838-a1eba2ee674b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data into Products_Dim table in CustomerManagementDWH\n",
    "products_df.to_sql('Products_Dim', engine_dwh, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0bdc7e58-c1cb-4d21-8d7c-1512d103d6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     DateID       Date  Day  Month  Year  Quarter    Weekday\n",
      "0  20200101 2020-01-01    1      1  2020        1  Wednesday\n",
      "1  20200102 2020-01-02    2      1  2020        1   Thursday\n",
      "2  20200103 2020-01-03    3      1  2020        1     Friday\n",
      "3  20200104 2020-01-04    4      1  2020        1   Saturday\n",
      "4  20200105 2020-01-05    5      1  2020        1     Sunday\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the start and end date for the date dimension\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2025-12-31'\n",
    "\n",
    "# Create a date range\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "\n",
    "# Create a DataFrame for the Date_Dim table\n",
    "date_dim_df = pd.DataFrame({\n",
    "    'Date': date_range,\n",
    "    'Day': date_range.day,\n",
    "    'Month': date_range.month,\n",
    "    'Year': date_range.year,\n",
    "    'Quarter': date_range.quarter,\n",
    "    'Weekday': date_range.strftime('%A')  # Convert weekday to a string like 'Monday'\n",
    "})\n",
    "\n",
    "# Create a unique DateID (YYYYMMDD format)\n",
    "date_dim_df['DateID'] = date_dim_df['Date'].dt.strftime('%Y%m%d').astype(int)\n",
    "\n",
    "# Reorder columns to match the target schema\n",
    "date_dim_df = date_dim_df[['DateID', 'Date', 'Day', 'Month', 'Year', 'Quarter', 'Weekday']]\n",
    "\n",
    "print(date_dim_df.head())  # Check the first few rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "03aca7de-1064-424b-b8c9-47e601f6dadf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data into Date_Dim table in CustomerManagementDWH\n",
    "date_dim_df.to_sql('Date_Dim', engine_dwh, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8f84f881-449c-4f7e-ab87-de9c3bf1fc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     ShippingAddress  \\\n",
      "0  00655 Debra Prairie Suite 552, Port Anthony, P...   \n",
      "1        0228 Morrow Knolls\\nSouth Kathryn, DC 26571   \n",
      "2  033 Holly Fields Suite 287, West Donnaview, KY...   \n",
      "3  0346 Johnson Stream Apt. 929, North Jamesfort,...   \n",
      "4          0393 Morgan Turnpike\\nTerryfort, MI 07625   \n",
      "\n",
      "                                      BillingAddress  \n",
      "0                           USNV Clark, FPO AE 98671  \n",
      "1            7204 Bell Park\\nChristinafort, TN 81193  \n",
      "2  34546 Flynn Valleys Suite 970, South Jillian, ...  \n",
      "3  73981 Carlos Squares Apt. 979, Josephchester, ...  \n",
      "4                   Unit 2422 Box 0422\\nDPO AA 93174  \n"
     ]
    }
   ],
   "source": [
    "# Extract data from Customers and Orders for addresses\n",
    "customers_addresses_df = pd.read_sql('SELECT DISTINCT ShippingAddress, BillingAddress FROM Customers', engine_cm)\n",
    "orders_addresses_df = pd.read_sql('SELECT DISTINCT ShippingAddress, BillingAddress FROM Orders', engine_cm)\n",
    "\n",
    "# Concatenate the two DataFrames to get all distinct addresses\n",
    "addresses_df = pd.concat([customers_addresses_df, orders_addresses_df]).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "print(addresses_df.head())  # Preview the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "837f0f67-5d6e-45cf-8900-76bc15da6046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         FullAddress           City State  \\\n",
      "0  00655 Debra Prairie Suite 552, Port Anthony, P...           None  None   \n",
      "1                                 0228 Morrow Knolls  South Kathryn         \n",
      "2  033 Holly Fields Suite 287, West Donnaview, KY...           None  None   \n",
      "3  0346 Johnson Stream Apt. 929, North Jamesfort,...           None  None   \n",
      "4                               0393 Morgan Turnpike      Terryfort         \n",
      "\n",
      "  Country PostalCode  AddressID  \n",
      "0    None       None          1  \n",
      "1     USA         DC          2  \n",
      "2    None       None          3  \n",
      "3    None       None          4  \n",
      "4     USA         MI          5  \n"
     ]
    }
   ],
   "source": [
    "# Splitting the address into components (assuming they follow a specific format)\n",
    "# Example: \"123 Main St Suite 100\\nSpringfield, IL 62704\"\n",
    "\n",
    "# Define a helper function to split the address into parts\n",
    "def split_address(address):\n",
    "    try:\n",
    "        parts = address.split('\\n')  # Split by newline first\n",
    "        full_address = parts[0]\n",
    "        city_state_zip = parts[1].split(',')  # Split city and state+zip\n",
    "        city = city_state_zip[0]\n",
    "        state_zip = city_state_zip[1].split(' ')  # Split state and zip\n",
    "        state = state_zip[0]\n",
    "        postal_code = state_zip[1]\n",
    "        return pd.Series([full_address, city, state, 'USA', postal_code])  # Assuming the country is USA\n",
    "    except:\n",
    "        return pd.Series([address, None, None, None, None])  # In case of any issues, fill with None\n",
    "\n",
    "# Apply the split function to both Shipping and Billing addresses\n",
    "addresses_df[['FullAddress', 'City', 'State', 'Country', 'PostalCode']] = addresses_df['ShippingAddress'].apply(split_address)\n",
    "\n",
    "# Drop the original ShippingAddress and BillingAddress columns\n",
    "addresses_df = addresses_df.drop(columns=['ShippingAddress', 'BillingAddress'])\n",
    "\n",
    "# Add a unique AddressID\n",
    "addresses_df['AddressID'] = range(1, len(addresses_df) + 1)\n",
    "\n",
    "print(addresses_df.head())  # Preview the transformed data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f23601ca-8142-4280-b7cf-4dbdfd482f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data into Address_Dim table in CustomerManagementDWH\n",
    "addresses_df.to_sql('Address_Dim', engine_dwh, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fa667e-8174-45eb-9f03-cf5d07891d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
